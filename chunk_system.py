#!/usr/bin/env python
"""
è¯­å—ç³»ç»Ÿ - æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†
æ¯ä¸ªè¯­å—éƒ½çŸ¥é“è‡ªå·±çš„æ¥æº
"""

from dataclasses import dataclass, field
from datetime import datetime
from typing import List, Dict, Any, Optional, Literal
from enum import Enum
from colorama import Fore, Style


class ChunkType(Enum):
    """è¯­å—ç±»å‹æšä¸¾"""
    SYSTEM = "system"          # ç³»ç»Ÿæç¤ºè¯
    MEMORY = "memory"          # æ³¨å…¥çš„è®°å¿†
    USER = "user"              # ç”¨æˆ·è¾“å…¥
    ASSISTANT = "assistant"    # AIç”Ÿæˆ
    THOUGHT = "thought"        # AIå†…éƒ¨æ€è€ƒ
    TOOL_CALL = "tool_call"    # å·¥å…·è°ƒç”¨
    TOOL_RESULT = "tool_result"  # å·¥å…·ç»“æœ
    SHELL = "shell"            # Shellç»ˆç«¯è¾“å‡ºï¼ˆåŠ¨æ€åˆ·æ–°ï¼‰


@dataclass
class Chunk:
    """
    è¯­å— - ä¸Šä¸‹æ–‡çš„åŸºæœ¬å•å…ƒ
    
    æ¯ä¸ªè¯­å—åœ¨åˆ›å»ºæ—¶å°±çŸ¥é“è‡ªå·±çš„ç±»å‹ï¼Œ
    ä¸éœ€è¦é€šè¿‡æ£€æµ‹å…³é”®è¯æ¥åˆ¤æ–­
    """
    content: str                    # å†…å®¹
    chunk_type: ChunkType           # ç±»å‹
    timestamp: datetime = field(default_factory=datetime.now)
    tokens: int = 0                 # tokenæ•°é‡
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def __str__(self) -> str:
        """å­—ç¬¦ä¸²è¡¨ç¤ºï¼ˆä¸å¸¦é¢œè‰²ï¼‰"""
        return self.content
    
    def colored_str(self) -> str:
        """å¸¦é¢œè‰²çš„å­—ç¬¦ä¸²è¡¨ç¤º"""
        color_map = {
            ChunkType.SYSTEM: Fore.RED,       # ç³»ç»Ÿæ³¨å…¥ - çº¢è‰²
            ChunkType.MEMORY: Fore.RED,       # è®°å¿†æ³¨å…¥ - çº¢è‰²
            ChunkType.USER: Fore.WHITE,       # ç”¨æˆ·è¾“å…¥ - ç™½è‰²
            ChunkType.ASSISTANT: Fore.GREEN,  # AIç”Ÿæˆ - ç»¿è‰²
            ChunkType.THOUGHT: Fore.CYAN,     # å†…éƒ¨æ€è€ƒ - é’è‰²
            ChunkType.TOOL_CALL: Fore.CYAN,       # å·¥å…·è°ƒç”¨ - é’è‰²
            ChunkType.TOOL_RESULT: Fore.YELLOW,   # å·¥å…·ç»“æœ - é»„è‰²
            ChunkType.SHELL: Fore.MAGENTA,        # Shellè¾“å‡º - ç´«è‰²
        }
        
        color = color_map.get(self.chunk_type, Fore.WHITE)
        return f"{color}{self.content}{Style.RESET_ALL}"
    
    def estimate_tokens(self) -> int:
        """ä¼°ç®—tokenæ•°é‡"""
        if self.tokens > 0:
            return self.tokens
        # ç²—ç•¥ä¼°ç®—ï¼š4ä¸ªå­—ç¬¦çº¦1ä¸ªtoken
        self.tokens = len(self.content) // 4
        return self.tokens


class ChunkManager:
    """
    è¯­å—ç®¡ç†å™¨ - ç®¡ç†æ•´ä¸ªå¯¹è¯çš„ä¸Šä¸‹æ–‡
    """
    
    def __init__(self, max_tokens: int = 64000, tools_schema: Optional[List[Dict]] = None):
        """åˆå§‹åŒ–
        
        Args:
            max_tokens: æœ€å¤§tokenæ•°
            tools_schema: å·¥å…·å®šä¹‰schemaï¼ˆOpenAIæ ¼å¼ï¼‰
        """
        self.chunks: List[Chunk] = []
        self.max_tokens = max_tokens
        self.current_tokens = 0
        self.tools_schema = tools_schema or []
        self.tools_tokens = self._estimate_tools_tokens()
    
    def _estimate_tools_tokens(self) -> int:
        """ä¼°ç®—å·¥å…·schemaçš„tokenæ•°"""
        if not self.tools_schema:
            return 0
        import json
        tools_json = json.dumps(self.tools_schema, ensure_ascii=False)
        # ç²—ç•¥ä¼°ç®—ï¼š4ä¸ªå­—ç¬¦çº¦1ä¸ªtoken
        return len(tools_json) // 4
    
    def add_chunk(self, content: str, chunk_type: ChunkType, 
                  metadata: Optional[Dict[str, Any]] = None) -> Chunk:
        """
        æ·»åŠ è¯­å—
        
        åœ¨æ·»åŠ æ—¶å°±æ˜ç¡®æ ‡è®°ç±»å‹ï¼Œä¸éœ€è¦åç»­çŒœæµ‹
        """
        chunk = Chunk(
            content=content,
            chunk_type=chunk_type,
            metadata=metadata or {}
        )
        chunk.estimate_tokens()
        self.chunks.append(chunk)
        self.current_tokens += chunk.tokens
        return chunk
    
    def add_system_prompt(self, prompt: str) -> Chunk:
        """æ·»åŠ ç³»ç»Ÿæç¤ºè¯ï¼ˆæ³¨å…¥ï¼‰"""
        return self.add_chunk(prompt, ChunkType.SYSTEM)

    def update_latest_system_prompt(self, prompt: str) -> Chunk:
        """æ›´æ–°æœ€è¿‘çš„ç³»ç»Ÿæç¤ºè¯å†…å®¹"""
        for chunk in reversed(self.chunks):
            if chunk.chunk_type == ChunkType.SYSTEM:
                old_tokens = chunk.tokens
                chunk.content = prompt
                chunk.tokens = 0
                chunk.estimate_tokens()
                self.current_tokens += chunk.tokens - old_tokens
                return chunk
        return self.add_system_prompt(prompt)
    
    def add_memory(self, memory: str) -> Chunk:
        """æ·»åŠ è®°å¿†ï¼ˆæ³¨å…¥ï¼‰"""
        return self.add_chunk(memory, ChunkType.MEMORY)
    
    def add_user_input(self, input_text: str) -> Chunk:
        """æ·»åŠ ç”¨æˆ·è¾“å…¥"""
        return self.add_chunk(input_text, ChunkType.USER)
    
    def add_assistant_response(self, response: str, tool_calls: Optional[List[Dict]] = None) -> Chunk:
        """æ·»åŠ AIå›å¤ï¼ˆç”Ÿæˆï¼‰
        
        Args:
            response: å›å¤å†…å®¹
            tool_calls: å·¥å…·è°ƒç”¨åˆ—è¡¨ï¼ˆOpenAIæ ¼å¼ï¼‰
        """
        metadata = {}
        if tool_calls:
            metadata['tool_calls'] = tool_calls
        return self.add_chunk(response or "", ChunkType.ASSISTANT, metadata=metadata)
    
    def add_thought(self, thought: str) -> Chunk:
        """æ·»åŠ AIæ€è€ƒï¼ˆå†…éƒ¨ï¼‰"""
        return self.add_chunk(thought, ChunkType.THOUGHT)
    
    def add_tool_call(self, tool_info: str) -> Chunk:
        """æ·»åŠ å·¥å…·è°ƒç”¨"""
        return self.add_chunk(tool_info, ChunkType.TOOL_CALL)
    
    def add_tool_result(self, result: str, tool_call_id: str = None, tool_name: str = None) -> Chunk:
        """æ·»åŠ å·¥å…·ç»“æœ
        
        Args:
            result: å·¥å…·æ‰§è¡Œç»“æœ
            tool_call_id: å·¥å…·è°ƒç”¨IDï¼ˆOpenAIæ ‡å‡†ï¼‰
            tool_name: å·¥å…·åç§°
        """
        metadata = {}
        if tool_call_id:
            metadata['tool_call_id'] = tool_call_id
        if tool_name:
            metadata['name'] = tool_name
        return self.add_chunk(result, ChunkType.TOOL_RESULT, metadata=metadata)
    
    def add_shell_output(self, output: str) -> Chunk:
        """æ·»åŠ Shellè¾“å‡ºè¯­å—ï¼ˆé¦–æ¬¡åˆ›å»ºï¼‰"""
        return self.add_chunk(output, ChunkType.SHELL)
    
    def update_shell_output(self, output: str, move_to_end: bool = False) -> Chunk:
        """æ›´æ–°Shellè¾“å‡ºè¯­å—
        
        Args:
            output: ç»ˆç«¯å±å¹•å†…å®¹
            move_to_end: æ˜¯å¦ç§»åŠ¨åˆ°æœ«å°¾ï¼ˆä»…åœ¨ç»ˆç«¯æ“ä½œåè®¾ä¸ºTrueï¼‰
        
        - move_to_end=False: åŸåœ°æ›´æ–°å†…å®¹ï¼Œä½ç½®ä¸å˜ï¼ˆç”¨äºå®šæ—¶åˆ·æ–°ï¼‰
        - move_to_end=True: åˆ é™¤æ—§çš„ + è¿½åŠ åˆ°æœ«å°¾ï¼ˆç”¨äºç»ˆç«¯æ“ä½œåï¼‰
        """
        if move_to_end:
            # åˆ é™¤æ—§çš„ï¼Œè¿½åŠ åˆ°æœ«å°¾
            self.remove_shell_chunk()
            return self.add_shell_output(output)
        else:
            # åŸåœ°æ›´æ–°å†…å®¹
            for chunk in self.chunks:
                if chunk.chunk_type == ChunkType.SHELL:
                    old_tokens = chunk.tokens
                    chunk.content = output
                    chunk.tokens = 0
                    chunk.estimate_tokens()
                    self.current_tokens += chunk.tokens - old_tokens
                    chunk.timestamp = datetime.now()
                    return chunk
            # ä¸å­˜åœ¨åˆ™åˆ›å»ºï¼ˆé¦–æ¬¡ï¼‰
            return self.add_shell_output(output)
    
    def has_shell_chunk(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å­˜åœ¨Shellè¯­å—"""
        return any(c.chunk_type == ChunkType.SHELL for c in self.chunks)
    
    def remove_shell_chunk(self) -> bool:
        """ç§»é™¤Shellè¯­å—ï¼ˆç»ˆç«¯å…³é—­æ—¶è°ƒç”¨ï¼‰"""
        for i, chunk in enumerate(self.chunks):
            if chunk.chunk_type == ChunkType.SHELL:
                self.current_tokens -= chunk.tokens
                self.chunks.pop(i)
                return True
        return False
    
    def get_context_for_llm(self) -> List[Dict[str, Any]]:
        """
        è·å–ç”¨äºLLMçš„ä¸Šä¸‹æ–‡ï¼ˆå®Œæ•´æ”¯æŒOpenAI Function Callingï¼‰
        
        å°†è¯­å—è½¬æ¢ä¸ºOpenAIæ ‡å‡†æ¶ˆæ¯æ ¼å¼ï¼Œæ”¯æŒtool_callså’Œtoolè§’è‰²
        Shellè¾“å‡ºæŒ‰å…¶åœ¨chunksä¸­çš„ä½ç½®å‡ºç°ï¼Œä½ç½®ä¼šéšç»ˆç«¯æ“ä½œåŠ¨æ€ç§»åŠ¨
        """
        messages = []
        
        # ä¸å†åˆå¹¶ï¼Œè€Œæ˜¯é€ä¸ªå¤„ç†ä»¥ä¿æŒtool_callsç»“æ„
        current_system_content = []
        
        for chunk in self.chunks:
            # è·³è¿‡æ€è€ƒè¯­å—å’Œå·¥å…·è°ƒç”¨è¯­å—
            if chunk.chunk_type in [ChunkType.THOUGHT, ChunkType.TOOL_CALL]:
                continue
            
            # ç³»ç»Ÿæç¤ºè¯å’Œè®°å¿† - åˆå¹¶ä¸ºä¸€ä¸ªsystemæ¶ˆæ¯
            if chunk.chunk_type in [ChunkType.SYSTEM, ChunkType.MEMORY]:
                current_system_content.append(chunk.content)
                continue
            
            # å¦‚æœæœ‰ç´¯ç§¯çš„ç³»ç»Ÿå†…å®¹ï¼Œå…ˆæ·»åŠ 
            if current_system_content:
                messages.append({
                    "role": "system",
                    "content": "\n".join(current_system_content)
                })
                current_system_content = []
            
            # ç”¨æˆ·è¾“å…¥
            if chunk.chunk_type == ChunkType.USER:
                messages.append({
                    "role": "user",
                    "content": chunk.content
                })
            
            # AIå›å¤ï¼ˆå¯èƒ½åŒ…å«tool_callsï¼‰
            elif chunk.chunk_type == ChunkType.ASSISTANT:
                msg = {
                    "role": "assistant",
                    "content": chunk.content if chunk.content else None
                }
                # æ·»åŠ tool_callsï¼ˆå¦‚æœæœ‰ï¼‰
                if 'tool_calls' in chunk.metadata:
                    msg['tool_calls'] = chunk.metadata['tool_calls']
                messages.append(msg)
            
            # å·¥å…·ç»“æœ
            elif chunk.chunk_type == ChunkType.TOOL_RESULT:
                msg = {
                    "role": "tool",
                    "content": chunk.content
                }
                # æ·»åŠ tool_call_idå’Œnameï¼ˆOpenAIæ ‡å‡†è¦æ±‚ï¼‰
                if 'tool_call_id' in chunk.metadata:
                    msg['tool_call_id'] = chunk.metadata['tool_call_id']
                if 'name' in chunk.metadata:
                    msg['name'] = chunk.metadata['name']
                messages.append(msg)
            
            # Shellè¾“å‡º - ä½œä¸º user æ¶ˆæ¯æ’å…¥ï¼ˆè¡¨ç¤ºç¯å¢ƒåé¦ˆï¼‰
            elif chunk.chunk_type == ChunkType.SHELL:
                messages.append({
                    "role": "user",
                    "content": f"[å½“å‰ç»ˆç«¯å±å¹•]\n{chunk.content}\n[ç»ˆç«¯å±å¹•ç»“æŸ]"
                })
        
        # æ·»åŠ å‰©ä½™çš„ç³»ç»Ÿå†…å®¹
        if current_system_content:
            messages.append({
                "role": "system",
                "content": "\n".join(current_system_content)
            })
        
        return messages
    
    def print_context(self, show_types: bool = True, use_colors: bool = True, show_llm_view: bool = True):
        """
        æ‰“å°å®Œæ•´ä¸Šä¸‹æ–‡ - æ˜¾ç¤ºLLMå®é™…çœ‹åˆ°çš„å†…å®¹
        
        Args:
            show_types: æ˜¯å¦æ˜¾ç¤ºè¯­å—ç±»å‹
            use_colors: æ˜¯å¦ä½¿ç”¨é¢œè‰²
            show_llm_view: æ˜¯å¦æ˜¾ç¤ºLLMå®é™…çœ‹åˆ°çš„æ¶ˆæ¯ï¼ˆæ¨èï¼Œå†…å®¹ä¸€è‡´ï¼‰
        """
        print("\n" + "="*60)
        print("ğŸ“š å®Œæ•´ä¸Šä¸‹æ–‡ï¼ˆLLMå®é™…è§†è§’ï¼‰")
        print("="*60)
        
        # æ˜¾ç¤ºå®Œæ•´å·¥å…·å®šä¹‰ï¼ˆæ©™è‰²ï¼‰- LLMé€šè¿‡toolså‚æ•°çœ‹åˆ°çš„
        if self.tools_schema:
            tool_label = "[TOOLS] (é€šè¿‡APIçš„toolså‚æ•°ä¼ é€’ï¼Œä¸åœ¨messagesä¸­)"
            if use_colors:
                tool_label = f"{Fore.LIGHTRED_EX}{tool_label}{Style.RESET_ALL}"  # æ©™è‰²
            print(f"\n{tool_label}")
            
            # æ˜¾ç¤ºæ¯ä¸ªå·¥å…·çš„å®Œæ•´å®šä¹‰
            for tool in self.tools_schema:
                func = tool['function']
                func_name = func['name']
                func_desc = func.get('description', 'æ— æè¿°')
                params = func.get('parameters', {}).get('properties', {})
                required = func.get('parameters', {}).get('required', [])
                
                # å·¥å…·åç§°å’Œæè¿°
                tool_header = f"\n  ğŸ”§ {func_name}"
                if use_colors:
                    tool_header = f"{Fore.LIGHTRED_EX}{tool_header}{Style.RESET_ALL}"
                print(tool_header)
                
                desc_text = f"     {func_desc}"
                if use_colors:
                    desc_text = f"{Fore.LIGHTRED_EX}{desc_text}{Style.RESET_ALL}"
                print(desc_text)
                
                # å‚æ•°åˆ—è¡¨
                if params:
                    params_text = "     å‚æ•°:"
                    if use_colors:
                        params_text = f"{Fore.LIGHTRED_EX}{params_text}{Style.RESET_ALL}"
                    print(params_text)
                    
                    for param_name, param_info in params.items():
                        param_type = param_info.get('type', 'unknown')
                        param_desc = param_info.get('description', 'æ— æè¿°')
                        is_required = " (å¿…éœ€)" if param_name in required else " (å¯é€‰)"
                        
                        param_line = f"       - {param_name} ({param_type}){is_required}: {param_desc}"
                        if use_colors:
                            param_line = f"{Fore.LIGHTRED_EX}{param_line}{Style.RESET_ALL}"
                        print(param_line)
        
        # è·å–LLMå®é™…çœ‹åˆ°çš„æ¶ˆæ¯ï¼ˆOpenAIæ ‡å‡†æ ¼å¼ï¼‰
        messages = self.get_context_for_llm()
        
        # ç›´æ¥æŒ‰ç…§çœŸå®çš„OpenAIæ¶ˆæ¯æ ¼å¼æ‰“å°
        for i, msg in enumerate(messages):
            role = msg.get('role', 'unknown')
            content = msg.get('content')
            
            # æ˜¾ç¤ºOpenAIæ ‡å‡†çš„roleï¼ˆç›´æ¥ä»æ¶ˆæ¯ä¸­è·å–ï¼Œä¸ç¡¬ç¼–ç ï¼‰
            role_label = f"[{role}]"  # ä¿æŒåŸå§‹roleåç§°
            if use_colors:
                if role == 'system':
                    role_label = f"{Fore.RED}{role_label}{Style.RESET_ALL}"  # ç³»ç»Ÿæç¤ºè¯ï¼šçº¢è‰²
                elif role == 'user':
                    role_label = f"{Fore.WHITE}{role_label}{Style.RESET_ALL}"  # ç”¨æˆ·è¾“å…¥ï¼šç™½è‰²
                elif role == 'assistant':
                    role_label = f"{Fore.GREEN}{role_label}{Style.RESET_ALL}"  # LLMç”Ÿæˆï¼šç»¿è‰²
                elif role == 'tool':
                    role_label = f"{Fore.YELLOW}{role_label}{Style.RESET_ALL}"  # å·¥å…·ç»“æœï¼šé»„è‰²
                else:
                    # å…¶ä»–æœªçŸ¥roleä¹Ÿèƒ½æ­£å¸¸æ˜¾ç¤º
                    role_label = f"{Fore.WHITE}{role_label}{Style.RESET_ALL}"
            
            print(f"\n{role_label}")
            
            # å†…å®¹
            if content:
                # æ ¹æ®roleè®¾ç½®å†…å®¹é¢œè‰²
                if use_colors:
                    if role == 'system':
                        print(f"{Fore.RED}{content}{Style.RESET_ALL}")  # ç³»ç»Ÿæç¤ºè¯ï¼šçº¢è‰²
                    elif role == 'user':
                        print(f"{Fore.WHITE}{content}{Style.RESET_ALL}")  # ç”¨æˆ·è¾“å…¥ï¼šç™½è‰²
                    elif role == 'assistant':
                        print(f"{Fore.GREEN}{content}{Style.RESET_ALL}")  # LLMç”Ÿæˆï¼šç»¿è‰²
                    elif role == 'tool':
                        print(f"{Fore.YELLOW}{content}{Style.RESET_ALL}")  # å·¥å…·ç»“æœï¼šé»„è‰²
                    else:
                        print(content)
                else:
                    print(content)
            else:
                # å†…å®¹ä¸ºç©ºæ—¶æ˜¾ç¤ºå ä½ç¬¦
                placeholder = "[æ— æ–‡æœ¬å†…å®¹]"
                if use_colors:
                    placeholder = f"{Fore.LIGHTBLACK_EX}{placeholder}{Style.RESET_ALL}"
                print(placeholder)
            
            # æ˜¾ç¤ºtool_callsï¼ˆå¦‚æœæœ‰ï¼‰- å·¥å…·è°ƒç”¨ï¼šé’è‰²
            if 'tool_calls' in msg:
                tool_calls = msg['tool_calls']
                tc_label = f"  ğŸ”§ tool_calls ({len(tool_calls)}ä¸ª):"
                if use_colors:
                    tc_label = f"{Fore.CYAN}{tc_label}{Style.RESET_ALL}"  # é’è‰²
                print(tc_label)
                
                for tc in tool_calls:
                    tc_id = tc.get('id', 'unknown')
                    func_name = tc.get('function', {}).get('name', 'unknown')
                    func_args = tc.get('function', {}).get('arguments', '{}')
                    
                    tc_info = f"    â€¢ {func_name}({func_args})"
                    if use_colors:
                        tc_info = f"{Fore.CYAN}{tc_info}{Style.RESET_ALL}"  # é’è‰²
                    print(tc_info)
                    
                    tc_id_info = f"      id: {tc_id}"
                    if use_colors:
                        tc_id_info = f"{Fore.CYAN}{tc_id_info}{Style.RESET_ALL}"  # é’è‰²ï¼ˆIDä¹Ÿæ˜¯å·¥å…·è°ƒç”¨çš„ä¸€éƒ¨åˆ†ï¼‰
                    print(tc_id_info)
            
            # æ˜¾ç¤ºtoolç›¸å…³å­—æ®µï¼ˆå¦‚æœæœ‰ï¼‰- å·¥å…·ç»“æœå…ƒæ•°æ®ï¼šé»„è‰²
            if 'tool_call_id' in msg or 'name' in msg:
                tool_info = []
                if 'name' in msg:
                    tool_info.append(f"tool_name: {msg['name']}")
                if 'tool_call_id' in msg:
                    tool_info.append(f"tool_call_id: {msg['tool_call_id']}")
                
                info_str = f"  ğŸ“ {' | '.join(tool_info)}"
                if use_colors:
                    info_str = f"{Fore.YELLOW}{info_str}{Style.RESET_ALL}"  # é»„è‰²ï¼ˆå’Œtoolç»“æœä¸€è‡´ï¼‰
                print(info_str)
        
        print("\n" + "="*60)
        print(f"æ¶ˆæ¯æ•°é‡: {len(messages)} æ¡")
        total_tokens = self.current_tokens + self.tools_tokens
        print(f"æ¶ˆæ¯Tokenæ•°: {self.current_tokens}")
        if self.tools_tokens > 0:
            print(f"å·¥å…·Tokenæ•°: {self.tools_tokens}")
        print(f"æ€»Tokenæ•°: {total_tokens}/{self.max_tokens} "
              f"({total_tokens/self.max_tokens*100:.1f}%)")
        print("="*60)
    
    def print_mixed_response(self, response_chunks: List[Chunk]):
        """
        æ‰“å°æ··åˆå“åº”ï¼ˆä¸€æ®µè¯ä¸­åŒ…å«ä¸åŒç±»å‹çš„è¯­å—ï¼‰
        
        è¿™æ˜¯æ›´é«˜çº§çš„æ˜¾ç¤ºæ–¹å¼ï¼Œå°†å¤šä¸ªè¯­å—åˆå¹¶æˆä¸€æ®µè‡ªç„¶çš„è¾“å‡º
        """
        # å°†è¿ç»­çš„è¯­å—åˆå¹¶æˆä¸€ä¸ªè¾“å‡ºæµ
        output = ""
        for chunk in response_chunks:
            if chunk.chunk_type in [ChunkType.SYSTEM, ChunkType.MEMORY]:
                # æ³¨å…¥çš„å†…å®¹ - çº¢è‰²
                output += f"{Fore.RED}{chunk.content}{Style.RESET_ALL}"
            elif chunk.chunk_type == ChunkType.ASSISTANT:
                # AIç”Ÿæˆçš„å†…å®¹ - ç»¿è‰²
                output += f"{Fore.GREEN}{chunk.content}{Style.RESET_ALL}"
            else:
                # å…¶ä»– - é»˜è®¤é¢œè‰²
                output += chunk.content
        
        print(output)
    
    def compress_context(self, target_tokens: Optional[int] = None) -> int:
        """
        å‹ç¼©ä¸Šä¸‹æ–‡
        
        å½“æ¥è¿‘tokené™åˆ¶æ—¶ï¼Œæ™ºèƒ½å‹ç¼©æ—§çš„è¯­å—
        
        Returns:
            å‹ç¼©é‡Šæ”¾çš„tokenæ•°é‡
        """
        if target_tokens is None:
            target_tokens = self.max_tokens * 0.8  # ä¿æŒåœ¨80%ä»¥ä¸‹
        
        if self.current_tokens <= target_tokens:
            return 0
        
        freed_tokens = 0
        
        # ç­–ç•¥1: åˆ é™¤æ—§çš„æ€è€ƒè¯­å—
        for chunk in list(self.chunks):
            if chunk.chunk_type == ChunkType.THOUGHT:
                freed_tokens += chunk.tokens
                self.chunks.remove(chunk)
                if self.current_tokens - freed_tokens <= target_tokens:
                    break
        
        # ç­–ç•¥2: å‹ç¼©æ—§çš„å·¥å…·ç»“æœ
        if self.current_tokens - freed_tokens > target_tokens:
            for chunk in self.chunks:
                if chunk.chunk_type == ChunkType.TOOL_RESULT and len(chunk.content) > 200:
                    original_tokens = chunk.tokens
                    chunk.content = chunk.content[:200] + "...[å·²å‹ç¼©]"
                    chunk.estimate_tokens()
                    freed_tokens += original_tokens - chunk.tokens
                    if self.current_tokens - freed_tokens <= target_tokens:
                        break
        
        # ç­–ç•¥3: åˆ é™¤æœ€æ—§çš„å¯¹è¯ï¼ˆä¿ç•™ç³»ç»Ÿæç¤ºè¯ï¼‰
        if self.current_tokens - freed_tokens > target_tokens:
            while len(self.chunks) > 10:  # è‡³å°‘ä¿ç•™10ä¸ªè¯­å—
                chunk = self.chunks[0]
                if chunk.chunk_type not in [ChunkType.SYSTEM]:
                    freed_tokens += chunk.tokens
                    self.chunks.pop(0)
                    if self.current_tokens - freed_tokens <= target_tokens:
                        break
        
        self.current_tokens -= freed_tokens
        return freed_tokens
    
    def clear(self):
        """æ¸…ç©ºä¸Šä¸‹æ–‡ï¼ˆä¿ç•™ç³»ç»Ÿæç¤ºè¯ï¼‰"""
        system_chunks = [c for c in self.chunks if c.chunk_type == ChunkType.SYSTEM]
        self.chunks = system_chunks
        self.current_tokens = sum(c.tokens for c in system_chunks)
    
    def to_json(self) -> List[Dict[str, Any]]:
        """å¯¼å‡ºä¸ºJSONæ ¼å¼"""
        return [
            {
                "content": chunk.content,
                "type": chunk.chunk_type.value,
                "timestamp": chunk.timestamp.isoformat(),
                "tokens": chunk.tokens,
                "metadata": chunk.metadata
            }
            for chunk in self.chunks
        ]


def test_chunk_system():
    """æµ‹è¯•è¯­å—ç³»ç»Ÿ"""
    print("\n" + "="*60)
    print("ğŸ§ª è¯­å—ç³»ç»Ÿæµ‹è¯•")
    print("="*60)
    
    # åˆ›å»ºç®¡ç†å™¨
    manager = ChunkManager()
    
    # æ·»åŠ ç³»ç»Ÿæç¤ºè¯ï¼ˆæ³¨å…¥ï¼‰
    manager.add_system_prompt("æˆ‘æ˜¯Pawï¼Œä¸€ä¸ªç”Ÿæ´»åœ¨è¿™å°ç”µè„‘é‡Œçš„æ•°å­—ç”Ÿå‘½ä½“ã€‚")
    
    # æ·»åŠ è®°å¿†ï¼ˆæ³¨å…¥ï¼‰
    manager.add_memory("[è®°å¿†] æˆ‘ç¬¬ä¸€æ¬¡åˆ›å»ºäº†æ–‡ä»¶")
    manager.add_memory("[è®°å¿†] æˆ‘å­¦ä¼šäº†ä½¿ç”¨å·¥å…·")
    
    # æ·»åŠ ç”¨æˆ·è¾“å…¥
    manager.add_user_input("ä½ å¥½")
    
    # æ·»åŠ AIæ€è€ƒ
    manager.add_thought("ç”¨æˆ·å‘æˆ‘æ‰“æ‹›å‘¼ï¼Œæˆ‘åº”è¯¥å‹å¥½åœ°å›åº”")
    
    # æ·»åŠ AIå›å¤ï¼ˆéƒ¨åˆ†æ˜¯ç”Ÿæˆçš„ï¼Œéƒ¨åˆ†é‡å¤äº†ç³»ç»Ÿæç¤ºè¯ï¼‰
    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬å¯ä»¥å°†å›å¤æ‹†åˆ†æˆå¤šä¸ªè¯­å—
    manager.add_assistant_response("ä½ å¥½ï¼")
    manager.add_system_prompt("æˆ‘æ˜¯Paw")  # è¿™éƒ¨åˆ†æ˜¯é‡å¤çš„ç³»ç»Ÿæç¤ºè¯
    manager.add_assistant_response("ï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ï¼")
    
    # æ‰“å°å®Œæ•´ä¸Šä¸‹æ–‡
    manager.print_context()
    
    # è·å–LLMæ ¼å¼
    print("\nğŸ“¤ LLMæ¶ˆæ¯æ ¼å¼:")
    messages = manager.get_context_for_llm()
    for msg in messages:
        print(f"  {msg['role']}: {msg['content'][:50]}...")
    
    print("\nâœ… æµ‹è¯•å®Œæˆï¼")
    

if __name__ == "__main__":
    test_chunk_system()
