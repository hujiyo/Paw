#!/usr/bin/env python
"""
è¯­å—ç³»ç»Ÿ - ä¸Šä¸‹æ–‡ç®¡ç†æ¶æ„
é€šè¿‡è¯­å—æ¥ç®¡ç†ä¸Šä¸‹æ–‡
"""

from dataclasses import dataclass, field
from datetime import datetime
from typing import List, Dict, Any, Optional, Literal, Tuple
from enum import Enum
from colorama import Fore, Style


class ChunkType(Enum):
    """è¯­å—ç±»å‹æšä¸¾"""
    SYSTEM = "system"          # ç³»ç»Ÿæç¤ºè¯
    MEMORY = "memory"          # æ³¨å…¥çš„è®°å¿†
    USER = "user"              # ç”¨æˆ·è¾“å…¥
    ASSISTANT = "assistant"    # AIç”Ÿæˆ
    THOUGHT = "thought"        # AIå†…éƒ¨æ€è€ƒ
    TOOL_CALL = "tool_call"    # å·¥å…·è°ƒç”¨
    TOOL_RESULT = "tool_result"  # å·¥å…·ç»“æœ
    SHELL = "shell"            # Shellç»ˆç«¯è¾“å‡ºï¼ˆåŠ¨æ€åˆ·æ–°ï¼‰


@dataclass
class Chunk:
    """
    è¯­å— - ä¸Šä¸‹æ–‡çš„åŸºæœ¬å•å…ƒ
    
    æ¯ä¸ªè¯­å—åœ¨åˆ›å»ºæ—¶å°±çŸ¥é“è‡ªå·±çš„ç±»å‹ï¼Œ
    ä¸éœ€è¦é€šè¿‡æ£€æµ‹å…³é”®è¯æ¥åˆ¤æ–­
    """
    content: str                    # å†…å®¹
    chunk_type: ChunkType           # ç±»å‹
    timestamp: datetime = field(default_factory=datetime.now)
    tokens: int = 0                 # tokenæ•°é‡
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def __str__(self) -> str:
        """å­—ç¬¦ä¸²è¡¨ç¤ºï¼ˆä¸å¸¦é¢œè‰²ï¼‰"""
        return self.content
    
    def colored_str(self) -> str:
        """å¸¦é¢œè‰²çš„å­—ç¬¦ä¸²è¡¨ç¤º"""
        color_map = {
            ChunkType.SYSTEM: Fore.RED,       # ç³»ç»Ÿæ³¨å…¥ - çº¢è‰²
            ChunkType.MEMORY: Fore.RED,       # è®°å¿†æ³¨å…¥ - çº¢è‰²
            ChunkType.USER: Fore.WHITE,       # ç”¨æˆ·è¾“å…¥ - ç™½è‰²
            ChunkType.ASSISTANT: Fore.GREEN,  # AIç”Ÿæˆ - ç»¿è‰²
            ChunkType.THOUGHT: Fore.CYAN,     # å†…éƒ¨æ€è€ƒ - é’è‰²
            ChunkType.TOOL_CALL: Fore.CYAN,       # å·¥å…·è°ƒç”¨ - é’è‰²
            ChunkType.TOOL_RESULT: Fore.YELLOW,   # å·¥å…·ç»“æœ - é»„è‰²
            ChunkType.SHELL: Fore.MAGENTA,        # Shellè¾“å‡º - ç´«è‰²
        }
        
        color = color_map.get(self.chunk_type, Fore.WHITE)
        return f"{color}{self.content}{Style.RESET_ALL}"
    
    def estimate_tokens(self) -> int:
        """ä¼°ç®—tokenæ•°é‡"""
        if self.tokens > 0:
            return self.tokens
        # ç²—ç•¥ä¼°ç®—ï¼š4ä¸ªå­—ç¬¦çº¦1ä¸ªtoken
        self.tokens = len(self.content) // 4
        return self.tokens


class ChunkManager:
    """
    è¯­å—ç®¡ç†å™¨ - ç®¡ç†æ•´ä¸ªå¯¹è¯çš„ä¸Šä¸‹æ–‡
    """
    
    def __init__(self, max_tokens: int = 64000, tools_schema: Optional[List[Dict]] = None):
        """åˆå§‹åŒ–
        
        Args:
            max_tokens: æœ€å¤§tokenæ•°
            tools_schema: å·¥å…·å®šä¹‰schemaï¼ˆOpenAIæ ¼å¼ï¼‰
        """
        self.chunks: List[Chunk] = []
        self.max_tokens = max_tokens
        self.current_tokens = 0
        self.tools_schema = tools_schema or []
        self.tools_tokens = self._estimate_tools_tokens()
    
    def _estimate_tools_tokens(self) -> int:
        """ä¼°ç®—å·¥å…·schemaçš„tokenæ•°"""
        if not self.tools_schema:
            return 0
        import json
        tools_json = json.dumps(self.tools_schema, ensure_ascii=False)
        # ç²—ç•¥ä¼°ç®—ï¼š4ä¸ªå­—ç¬¦çº¦1ä¸ªtoken
        return len(tools_json) // 4
    
    def add_chunk(self, content: str, chunk_type: ChunkType, 
                  metadata: Optional[Dict[str, Any]] = None) -> Chunk:
        """
        æ·»åŠ è¯­å—
        
        åœ¨æ·»åŠ æ—¶å°±æ˜ç¡®æ ‡è®°ç±»å‹ï¼Œä¸éœ€è¦åç»­çŒœæµ‹
        """
        chunk = Chunk(
            content=content,
            chunk_type=chunk_type,
            metadata=metadata or {}
        )
        chunk.estimate_tokens()
        self.chunks.append(chunk)
        self.current_tokens += chunk.tokens
        return chunk
    
    def add_system_prompt(self, prompt: str) -> Chunk:
        """æ·»åŠ ç³»ç»Ÿæç¤ºè¯ï¼ˆæ³¨å…¥ï¼‰"""
        return self.add_chunk(prompt, ChunkType.SYSTEM)

    def update_latest_system_prompt(self, prompt: str) -> Chunk:
        """æ›´æ–°æœ€è¿‘çš„ç³»ç»Ÿæç¤ºè¯å†…å®¹"""
        for chunk in reversed(self.chunks):
            if chunk.chunk_type == ChunkType.SYSTEM:
                old_tokens = chunk.tokens
                chunk.content = prompt
                chunk.tokens = 0
                chunk.estimate_tokens()
                self.current_tokens += chunk.tokens - old_tokens
                return chunk
        return self.add_system_prompt(prompt)
    
    def add_memory(self, memory: str) -> Chunk:
        """æ·»åŠ è®°å¿†ï¼ˆæ³¨å…¥ï¼‰"""
        return self.add_chunk(memory, ChunkType.MEMORY)
    
    def update_or_add_memory(self, memory: str) -> Chunk:
        """æ›´æ–°æˆ–æ·»åŠ è®°å¿† chunk
        
        å¦‚æœå·²å­˜åœ¨ MEMORY chunkï¼Œåˆ™æ›¿æ¢å…¶å†…å®¹ï¼›å¦åˆ™æ–°å»ºã€‚
        ç¡®ä¿ä¸Šä¸‹æ–‡ä¸­åªæœ‰ä¸€ä¸ªè®°å¿† chunkã€‚
        """
        for chunk in self.chunks:
            if chunk.chunk_type == ChunkType.MEMORY:
                old_tokens = chunk.tokens
                chunk.content = memory
                chunk.tokens = 0
                chunk.estimate_tokens()
                self.current_tokens += chunk.tokens - old_tokens
                return chunk
        return self.add_memory(memory)
    
    def remove_memory(self):
        """ç§»é™¤è®°å¿† chunk"""
        for i, chunk in enumerate(self.chunks):
            if chunk.chunk_type == ChunkType.MEMORY:
                self.current_tokens -= chunk.tokens
                self.chunks.pop(i)
                return True
        return False
    
    def add_user_input(self, input_text: str) -> Chunk:
        """æ·»åŠ ç”¨æˆ·è¾“å…¥"""
        return self.add_chunk(input_text, ChunkType.USER)
    
    def add_assistant_response(self, response: str, tool_calls: Optional[List[Dict]] = None) -> Chunk:
        """æ·»åŠ AIå›å¤ï¼ˆç”Ÿæˆï¼‰
        
        Args:
            response: å›å¤å†…å®¹
            tool_calls: å·¥å…·è°ƒç”¨åˆ—è¡¨ï¼ˆOpenAIæ ¼å¼ï¼‰
        """
        metadata = {}
        if tool_calls:
            metadata['tool_calls'] = tool_calls
        return self.add_chunk(response or "", ChunkType.ASSISTANT, metadata=metadata)
    
    def add_thought(self, thought: str) -> Chunk:
        """æ·»åŠ AIæ€è€ƒï¼ˆå†…éƒ¨ï¼‰"""
        return self.add_chunk(thought, ChunkType.THOUGHT)
    
    def add_tool_call(self, tool_info: str) -> Chunk:
        """æ·»åŠ å·¥å…·è°ƒç”¨"""
        return self.add_chunk(tool_info, ChunkType.TOOL_CALL)
    
    def add_tool_result(self, result: str, tool_call_id: str = None, tool_name: str = None,
                        max_call_pairs: int = 0, display_info: dict = None) -> Chunk:
        """æ·»åŠ å·¥å…·ç»“æœ

        Args:
            result: å·¥å…·æ‰§è¡Œç»“æœ
            tool_call_id: å·¥å…·è°ƒç”¨IDï¼ˆOpenAIæ ‡å‡†ï¼‰
            tool_name: å·¥å…·åç§°
            max_call_pairs: æœ€å¤§é…å¯¹æ•°é‡ï¼Œè¶…å‡ºæ—¶åˆ é™¤æœ€æ—§çš„ (tool_call + tool_result)
            display_info: å·¥å…·æ˜¾ç¤ºä¿¡æ¯ï¼ˆç”¨äºæ¢å¤å†å²æ—¶ä¿æŒæ˜¾ç¤ºä¸€è‡´æ€§ï¼‰ï¼ŒåŒ…å« line1/line2/has_line2
        """
        metadata = {}
        if tool_call_id:
            metadata['tool_call_id'] = tool_call_id
        if tool_name:
            metadata['name'] = tool_name
        if display_info:
            metadata['display'] = display_info

        # æ·»åŠ æ–°çš„ tool_result
        chunk = self.add_chunk(result, ChunkType.TOOL_RESULT, metadata=metadata)

        # å¦‚æœè®¾ç½®äº† max_call_pairsï¼Œæ‰§è¡Œé…å¯¹æ¸…ç†
        if max_call_pairs > 0 and tool_name:
            self._enforce_max_call_pairs(tool_name, max_call_pairs)

        return chunk
    
    def _enforce_max_call_pairs(self, tool_name: str, max_pairs: int):
        """
        å¼ºåˆ¶æ‰§è¡Œé…å¯¹æ•°é‡é™åˆ¶
        
        åˆ é™¤æœ€æ—§çš„ (tool_call + tool_result) é…å¯¹ï¼Œç›´åˆ°æ•°é‡ <= max_pairs
        """
        # 1. æ‰¾å‡ºè¯¥å·¥å…·çš„æ‰€æœ‰ tool_result åŠå…¶ tool_call_id
        tool_results = []
        for i, chunk in enumerate(self.chunks):
            if (chunk.chunk_type == ChunkType.TOOL_RESULT and 
                chunk.metadata.get('name') == tool_name):
                tool_results.append({
                    'index': i,
                    'chunk': chunk,
                    'tool_call_id': chunk.metadata.get('tool_call_id')
                })
        
        # 2. å¦‚æœæ•°é‡è¶…è¿‡é™åˆ¶ï¼Œåˆ é™¤æœ€æ—§çš„é…å¯¹
        while len(tool_results) > max_pairs:
            oldest = tool_results.pop(0)  # æœ€æ—§çš„
            tool_call_id = oldest['tool_call_id']
            
            # åˆ é™¤å¯¹åº”çš„ tool_callï¼ˆåœ¨ assistant æ¶ˆæ¯çš„ tool_calls ä¸­ï¼‰
            self._remove_tool_call_by_id(tool_call_id)
            
            # åˆ é™¤ tool_result chunk
            self._remove_chunk_by_tool_call_id(tool_call_id)
    
    def _remove_tool_call_by_id(self, tool_call_id: str):
        """
        ä» assistant æ¶ˆæ¯ä¸­ç§»é™¤æŒ‡å®šçš„ tool_call
        
        å¦‚æœ assistant æ¶ˆæ¯çš„ tool_calls å˜ç©ºï¼Œåˆ™åˆ é™¤æ•´ä¸ª assistant æ¶ˆæ¯
        """
        for i, chunk in enumerate(self.chunks):
            if chunk.chunk_type == ChunkType.ASSISTANT and 'tool_calls' in chunk.metadata:
                tool_calls = chunk.metadata['tool_calls']
                # æ‰¾åˆ°å¹¶ç§»é™¤åŒ¹é…çš„ tool_call
                new_tool_calls = [tc for tc in tool_calls if tc.get('id') != tool_call_id]
                
                if len(new_tool_calls) < len(tool_calls):
                    # æ‰¾åˆ°äº†ï¼Œæ›´æ–°æˆ–åˆ é™¤
                    if len(new_tool_calls) == 0 and not chunk.content:
                        # tool_calls ä¸ºç©ºä¸”æ— æ–‡æœ¬å†…å®¹ï¼Œåˆ é™¤æ•´ä¸ª assistant chunk
                        self.current_tokens -= chunk.tokens
                        self.chunks.pop(i)
                    else:
                        # è¿˜æœ‰å…¶ä»– tool_calls æˆ–æœ‰æ–‡æœ¬å†…å®¹ï¼Œåªæ›´æ–°
                        chunk.metadata['tool_calls'] = new_tool_calls
                    return
    
    def _remove_chunk_by_tool_call_id(self, tool_call_id: str):
        """åˆ é™¤æŒ‡å®š tool_call_id çš„ tool_result chunk"""
        for i, chunk in enumerate(self.chunks):
            if (chunk.chunk_type == ChunkType.TOOL_RESULT and 
                chunk.metadata.get('tool_call_id') == tool_call_id):
                self.current_tokens -= chunk.tokens
                self.chunks.pop(i)
                return
    
    def add_shell_output(self, output: str) -> Chunk:
        """æ·»åŠ Shellè¾“å‡ºè¯­å—ï¼ˆé¦–æ¬¡åˆ›å»ºï¼‰"""
        return self.add_chunk(output, ChunkType.SHELL)
    
    def update_shell_output(self, output: str, move_to_end: bool = False) -> Chunk:
        """æ›´æ–°Shellè¾“å‡ºè¯­å—

        Args:
            output: ç»ˆç«¯å±å¹•å†…å®¹
            move_to_end: æ˜¯å¦ç§»åŠ¨åˆ°æœ«å°¾ï¼ˆä»…åœ¨ç»ˆç«¯æ“ä½œåè®¾ä¸ºTrueï¼‰

        - move_to_end=False: åŸåœ°æ›´æ–°å†…å®¹ï¼Œä½ç½®ä¸å˜ï¼ˆç”¨äºå®šæ—¶åˆ·æ–°ï¼‰
        - move_to_end=True: ä¿ç•™å†å²å†…å®¹ï¼Œè¿½åŠ æ–°è¾“å‡ºåˆ°æœ«å°¾ï¼ˆç”¨äºç»ˆç«¯æ“ä½œåï¼‰
        """
        if move_to_end:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ shell_chunk
            existing_content = None
            for chunk in self.chunks:
                if chunk.chunk_type == ChunkType.SHELL:
                    existing_content = chunk.content
                    self.remove_shell_chunk()
                    break

            # å¦‚æœæœ‰æ—§å†…å®¹ï¼Œè¿½åŠ æ–°è¾“å‡ºï¼ˆç”¨åˆ†éš”çº¿åˆ†å¼€ï¼‰
            if existing_content:
                combined = existing_content.rstrip() + "\n\n=== æ–°ç»ˆç«¯ ===\n" + output
                return self.add_shell_output(combined)
            else:
                return self.add_shell_output(output)
        else:
            # åŸåœ°æ›´æ–°å†…å®¹
            for chunk in self.chunks:
                if chunk.chunk_type == ChunkType.SHELL:
                    old_tokens = chunk.tokens
                    chunk.content = output
                    chunk.tokens = 0
                    chunk.estimate_tokens()
                    self.current_tokens += chunk.tokens - old_tokens
                    chunk.timestamp = datetime.now()
                    return chunk
            # ä¸å­˜åœ¨åˆ™åˆ›å»ºï¼ˆé¦–æ¬¡ï¼‰
            return self.add_shell_output(output)
    
    def has_shell_chunk(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å­˜åœ¨Shellè¯­å—"""
        return any(c.chunk_type == ChunkType.SHELL for c in self.chunks)
    
    def remove_shell_chunk(self) -> bool:
        """ç§»é™¤Shellè¯­å—ï¼ˆç»ˆç«¯å…³é—­æ—¶è°ƒç”¨ï¼‰"""
        for i, chunk in enumerate(self.chunks):
            if chunk.chunk_type == ChunkType.SHELL:
                self.current_tokens -= chunk.tokens
                self.chunks.pop(i)
                return True
        return False
    
    def get_context_for_llm(self) -> List[Dict[str, Any]]:
        """
        è·å–ç”¨äºLLMçš„ä¸Šä¸‹æ–‡ï¼ˆå®Œæ•´æ”¯æŒOpenAI Function Callingï¼‰
        
        å°†è¯­å—è½¬æ¢ä¸ºOpenAIæ ‡å‡†æ¶ˆæ¯æ ¼å¼ï¼Œæ”¯æŒtool_callså’Œtoolè§’è‰²
        Shellè¾“å‡ºæŒ‰å…¶åœ¨chunksä¸­çš„ä½ç½®å‡ºç°ï¼Œä½ç½®ä¼šéšç»ˆç«¯æ“ä½œåŠ¨æ€ç§»åŠ¨
        """
        messages = []
        
        # ä¸å†åˆå¹¶ï¼Œè€Œæ˜¯é€ä¸ªå¤„ç†ä»¥ä¿æŒtool_callsç»“æ„
        current_system_content = []
        
        for chunk in self.chunks:
            # è·³è¿‡æ€è€ƒè¯­å—å’Œå·¥å…·è°ƒç”¨è¯­å—
            if chunk.chunk_type in [ChunkType.THOUGHT, ChunkType.TOOL_CALL]:
                continue
            
            # ç³»ç»Ÿæç¤ºè¯å’Œè®°å¿† - åˆå¹¶ä¸ºä¸€ä¸ªsystemæ¶ˆæ¯
            if chunk.chunk_type in [ChunkType.SYSTEM, ChunkType.MEMORY]:
                current_system_content.append(chunk.content)
                continue
            
            # å¦‚æœæœ‰ç´¯ç§¯çš„ç³»ç»Ÿå†…å®¹ï¼Œå…ˆæ·»åŠ 
            if current_system_content:
                messages.append({
                    "role": "system",
                    "content": "\n".join(current_system_content)
                })
                current_system_content = []
            
            # ç”¨æˆ·è¾“å…¥
            if chunk.chunk_type == ChunkType.USER:
                messages.append({
                    "role": "user",
                    "content": chunk.content
                })
            
            # AIå›å¤ï¼ˆå¯èƒ½åŒ…å«tool_callsï¼‰
            elif chunk.chunk_type == ChunkType.ASSISTANT:
                msg = {
                    "role": "assistant",
                    "content": chunk.content if chunk.content else None
                }
                # æ·»åŠ tool_callsï¼ˆå¦‚æœæœ‰ï¼‰
                if 'tool_calls' in chunk.metadata:
                    msg['tool_calls'] = chunk.metadata['tool_calls']
                messages.append(msg)
            
            # å·¥å…·ç»“æœ
            elif chunk.chunk_type == ChunkType.TOOL_RESULT:
                msg = {
                    "role": "tool",
                    "content": chunk.content
                }
                # æ·»åŠ tool_call_idå’Œnameï¼ˆOpenAIæ ‡å‡†è¦æ±‚ï¼‰
                if 'tool_call_id' in chunk.metadata:
                    msg['tool_call_id'] = chunk.metadata['tool_call_id']
                if 'name' in chunk.metadata:
                    msg['name'] = chunk.metadata['name']
                messages.append(msg)
            
            # Shellè¾“å‡º - ä½œä¸º user æ¶ˆæ¯æ’å…¥ï¼ˆè¡¨ç¤ºç¯å¢ƒåé¦ˆï¼‰
            elif chunk.chunk_type == ChunkType.SHELL:
                messages.append({
                    "role": "user",
                    "content": f"[å½“å‰ç»ˆç«¯å±å¹•]\n{chunk.content}\n[ç»ˆç«¯å±å¹•ç»“æŸ]"
                })
        
        # æ·»åŠ å‰©ä½™çš„ç³»ç»Ÿå†…å®¹
        if current_system_content:
            messages.append({
                "role": "system",
                "content": "\n".join(current_system_content)
            })
        
        return messages
    
    def print_context(self, show_types: bool = True, use_colors: bool = True, show_llm_view: bool = True):
        """
        æ‰“å°å®Œæ•´ä¸Šä¸‹æ–‡ - æ˜¾ç¤ºLLMå®é™…çœ‹åˆ°çš„å†…å®¹
        
        Args:
            show_types: æ˜¯å¦æ˜¾ç¤ºè¯­å—ç±»å‹
            use_colors: æ˜¯å¦ä½¿ç”¨é¢œè‰²
            show_llm_view: æ˜¯å¦æ˜¾ç¤ºLLMå®é™…çœ‹åˆ°çš„æ¶ˆæ¯ï¼ˆæ¨èï¼Œå†…å®¹ä¸€è‡´ï¼‰
        """
        print("\n" + "="*60)
        print("ğŸ“š å®Œæ•´ä¸Šä¸‹æ–‡ï¼ˆLLMå®é™…è§†è§’ï¼‰")
        print("="*60)
        
        # æ˜¾ç¤ºå®Œæ•´å·¥å…·å®šä¹‰ï¼ˆæ©™è‰²ï¼‰- LLMé€šè¿‡toolså‚æ•°çœ‹åˆ°çš„
        if self.tools_schema:
            tool_label = "[TOOLS] (é€šè¿‡APIçš„toolså‚æ•°ä¼ é€’ï¼Œä¸åœ¨messagesä¸­)"
            if use_colors:
                tool_label = f"{Fore.LIGHTRED_EX}{tool_label}{Style.RESET_ALL}"  # æ©™è‰²
            print(f"\n{tool_label}")
            
            # æ˜¾ç¤ºæ¯ä¸ªå·¥å…·çš„å®Œæ•´å®šä¹‰
            for tool in self.tools_schema:
                func = tool['function']
                func_name = func['name']
                func_desc = func.get('description', 'æ— æè¿°')
                params = func.get('parameters', {}).get('properties', {})
                required = func.get('parameters', {}).get('required', [])
                
                # å·¥å…·åç§°å’Œæè¿°
                tool_header = f"\n  ğŸ”§ {func_name}"
                if use_colors:
                    tool_header = f"{Fore.LIGHTRED_EX}{tool_header}{Style.RESET_ALL}"
                print(tool_header)
                
                desc_text = f"     {func_desc}"
                if use_colors:
                    desc_text = f"{Fore.LIGHTRED_EX}{desc_text}{Style.RESET_ALL}"
                print(desc_text)
                
                # å‚æ•°åˆ—è¡¨
                if params:
                    params_text = "     å‚æ•°:"
                    if use_colors:
                        params_text = f"{Fore.LIGHTRED_EX}{params_text}{Style.RESET_ALL}"
                    print(params_text)
                    
                    for param_name, param_info in params.items():
                        param_type = param_info.get('type', 'unknown')
                        param_desc = param_info.get('description', 'æ— æè¿°')
                        is_required = " (å¿…éœ€)" if param_name in required else " (å¯é€‰)"
                        
                        param_line = f"       - {param_name} ({param_type}){is_required}: {param_desc}"
                        if use_colors:
                            param_line = f"{Fore.LIGHTRED_EX}{param_line}{Style.RESET_ALL}"
                        print(param_line)
        
        # è·å–LLMå®é™…çœ‹åˆ°çš„æ¶ˆæ¯ï¼ˆOpenAIæ ‡å‡†æ ¼å¼ï¼‰
        messages = self.get_context_for_llm()
        
        # ç›´æ¥æŒ‰ç…§çœŸå®çš„OpenAIæ¶ˆæ¯æ ¼å¼æ‰“å°
        for i, msg in enumerate(messages):
            role = msg.get('role', 'unknown')
            content = msg.get('content')
            
            # æ˜¾ç¤ºOpenAIæ ‡å‡†çš„roleï¼ˆç›´æ¥ä»æ¶ˆæ¯ä¸­è·å–ï¼Œä¸ç¡¬ç¼–ç ï¼‰
            role_label = f"[{role}]"  # ä¿æŒåŸå§‹roleåç§°
            if use_colors:
                if role == 'system':
                    role_label = f"{Fore.RED}{role_label}{Style.RESET_ALL}"  # ç³»ç»Ÿæç¤ºè¯ï¼šçº¢è‰²
                elif role == 'user':
                    role_label = f"{Fore.WHITE}{role_label}{Style.RESET_ALL}"  # ç”¨æˆ·è¾“å…¥ï¼šç™½è‰²
                elif role == 'assistant':
                    role_label = f"{Fore.GREEN}{role_label}{Style.RESET_ALL}"  # LLMç”Ÿæˆï¼šç»¿è‰²
                elif role == 'tool':
                    role_label = f"{Fore.YELLOW}{role_label}{Style.RESET_ALL}"  # å·¥å…·ç»“æœï¼šé»„è‰²
                else:
                    # å…¶ä»–æœªçŸ¥roleä¹Ÿèƒ½æ­£å¸¸æ˜¾ç¤º
                    role_label = f"{Fore.WHITE}{role_label}{Style.RESET_ALL}"
            
            print(f"\n{role_label}")
            
            # å†…å®¹
            if content:
                # æ ¹æ®roleè®¾ç½®å†…å®¹é¢œè‰²
                if use_colors:
                    if role == 'system':
                        print(f"{Fore.RED}{content}{Style.RESET_ALL}")  # ç³»ç»Ÿæç¤ºè¯ï¼šçº¢è‰²
                    elif role == 'user':
                        print(f"{Fore.WHITE}{content}{Style.RESET_ALL}")  # ç”¨æˆ·è¾“å…¥ï¼šç™½è‰²
                    elif role == 'assistant':
                        print(f"{Fore.GREEN}{content}{Style.RESET_ALL}")  # LLMç”Ÿæˆï¼šç»¿è‰²
                    elif role == 'tool':
                        print(f"{Fore.YELLOW}{content}{Style.RESET_ALL}")  # å·¥å…·ç»“æœï¼šé»„è‰²
                    else:
                        print(content)
                else:
                    print(content)
            else:
                # å†…å®¹ä¸ºç©ºæ—¶æ˜¾ç¤ºå ä½ç¬¦
                placeholder = "[æ— æ–‡æœ¬å†…å®¹]"
                if use_colors:
                    placeholder = f"{Fore.LIGHTBLACK_EX}{placeholder}{Style.RESET_ALL}"
                print(placeholder)
            
            # æ˜¾ç¤ºtool_callsï¼ˆå¦‚æœæœ‰ï¼‰- å·¥å…·è°ƒç”¨ï¼šé’è‰²
            if 'tool_calls' in msg:
                tool_calls = msg['tool_calls']
                tc_label = f"  ğŸ”§ tool_calls ({len(tool_calls)}ä¸ª):"
                if use_colors:
                    tc_label = f"{Fore.CYAN}{tc_label}{Style.RESET_ALL}"  # é’è‰²
                print(tc_label)
                
                for tc in tool_calls:
                    tc_id = tc.get('id', 'unknown')
                    func_name = tc.get('function', {}).get('name', 'unknown')
                    func_args = tc.get('function', {}).get('arguments', '{}')
                    
                    tc_info = f"    â€¢ {func_name}({func_args})"
                    if use_colors:
                        tc_info = f"{Fore.CYAN}{tc_info}{Style.RESET_ALL}"  # é’è‰²
                    print(tc_info)
                    
                    tc_id_info = f"      id: {tc_id}"
                    if use_colors:
                        tc_id_info = f"{Fore.CYAN}{tc_id_info}{Style.RESET_ALL}"  # é’è‰²ï¼ˆIDä¹Ÿæ˜¯å·¥å…·è°ƒç”¨çš„ä¸€éƒ¨åˆ†ï¼‰
                    print(tc_id_info)
            
            # æ˜¾ç¤ºtoolç›¸å…³å­—æ®µï¼ˆå¦‚æœæœ‰ï¼‰- å·¥å…·ç»“æœå…ƒæ•°æ®ï¼šé»„è‰²
            if 'tool_call_id' in msg or 'name' in msg:
                tool_info = []
                if 'name' in msg:
                    tool_info.append(f"tool_name: {msg['name']}")
                if 'tool_call_id' in msg:
                    tool_info.append(f"tool_call_id: {msg['tool_call_id']}")
                
                info_str = f"  ğŸ“ {' | '.join(tool_info)}"
                if use_colors:
                    info_str = f"{Fore.YELLOW}{info_str}{Style.RESET_ALL}"  # é»„è‰²ï¼ˆå’Œtoolç»“æœä¸€è‡´ï¼‰
                print(info_str)
        
        print("\n" + "="*60)
        print(f"æ¶ˆæ¯æ•°é‡: {len(messages)} æ¡")
        total_tokens = self.current_tokens + self.tools_tokens
        print(f"æ¶ˆæ¯Tokenæ•°: {self.current_tokens}")
        if self.tools_tokens > 0:
            print(f"å·¥å…·Tokenæ•°: {self.tools_tokens}")
        print(f"æ€»Tokenæ•°: {total_tokens}/{self.max_tokens} "
              f"({total_tokens/self.max_tokens*100:.1f}%)")
        print("="*60)
    
    def print_mixed_response(self, response_chunks: List[Chunk]):
        """
        æ‰“å°æ··åˆå“åº”ï¼ˆä¸€æ®µè¯ä¸­åŒ…å«ä¸åŒç±»å‹çš„è¯­å—ï¼‰
        
        è¿™æ˜¯æ›´é«˜çº§çš„æ˜¾ç¤ºæ–¹å¼ï¼Œå°†å¤šä¸ªè¯­å—åˆå¹¶æˆä¸€æ®µè‡ªç„¶çš„è¾“å‡º
        """
        # å°†è¿ç»­çš„è¯­å—åˆå¹¶æˆä¸€ä¸ªè¾“å‡ºæµ
        output = ""
        for chunk in response_chunks:
            if chunk.chunk_type in [ChunkType.SYSTEM, ChunkType.MEMORY]:
                # æ³¨å…¥çš„å†…å®¹ - çº¢è‰²
                output += f"{Fore.RED}{chunk.content}{Style.RESET_ALL}"
            elif chunk.chunk_type == ChunkType.ASSISTANT:
                # AIç”Ÿæˆçš„å†…å®¹ - ç»¿è‰²
                output += f"{Fore.GREEN}{chunk.content}{Style.RESET_ALL}"
            else:
                # å…¶ä»– - é»˜è®¤é¢œè‰²
                output += chunk.content
        
        print(output)
    
    def clear(self):
        """æ¸…ç©ºä¸Šä¸‹æ–‡ï¼ˆä¿ç•™ç³»ç»Ÿæç¤ºè¯ï¼‰"""
        system_chunks = [c for c in self.chunks if c.chunk_type == ChunkType.SYSTEM]
        self.chunks = system_chunks
        self.current_tokens = sum(c.tokens for c in system_chunks)
    
    # ==================== å¯¹è¯ç¼–è¾‘åŠŸèƒ½ ====================
    
    def get_editable_chunks(self) -> List[Tuple[int, 'Chunk']]:
        """è·å–å¯ç¼–è¾‘çš„è¯­å—åˆ—è¡¨ï¼ˆæ’é™¤ç³»ç»Ÿæç¤ºè¯ï¼‰
        
        Returns:
            [(index, chunk), ...] åˆ—è¡¨ï¼Œindex æ˜¯åœ¨ self.chunks ä¸­çš„çœŸå®ç´¢å¼•
        """
        editable = []
        for i, chunk in enumerate(self.chunks):
            # æ’é™¤ç³»ç»Ÿæç¤ºè¯å’Œè®°å¿†ï¼ˆè¿™äº›æ˜¯æ³¨å…¥çš„ï¼Œä¸åº”è¯¥è¢«ç”¨æˆ·ç¼–è¾‘ï¼‰
            if chunk.chunk_type not in [ChunkType.SYSTEM, ChunkType.MEMORY]:
                editable.append((i, chunk))
        return editable
    
    def get_chunk_by_index(self, index: int) -> Optional['Chunk']:
        """æ ¹æ®ç´¢å¼•è·å–è¯­å—"""
        if 0 <= index < len(self.chunks):
            return self.chunks[index]
        return None
    
    def delete_chunk(self, index: int) -> bool:
        """åˆ é™¤æŒ‡å®šç´¢å¼•çš„è¯­å—
        
        Args:
            index: åœ¨ self.chunks ä¸­çš„çœŸå®ç´¢å¼•
            
        Returns:
            æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        if 0 <= index < len(self.chunks):
            chunk = self.chunks[index]
            # ä¸å…è®¸åˆ é™¤ç³»ç»Ÿæç¤ºè¯
            if chunk.chunk_type == ChunkType.SYSTEM:
                return False
            
            # å¦‚æœæ˜¯ assistant æ¶ˆæ¯ä¸”æœ‰ tool_callsï¼Œéœ€è¦åŒæ—¶åˆ é™¤å¯¹åº”çš„ tool_result
            if chunk.chunk_type == ChunkType.ASSISTANT and 'tool_calls' in chunk.metadata:
                tool_call_ids = [tc.get('id') for tc in chunk.metadata['tool_calls']]
                # åˆ é™¤å¯¹åº”çš„ tool_result
                self.chunks = [
                    c for c in self.chunks 
                    if not (c.chunk_type == ChunkType.TOOL_RESULT and 
                           c.metadata.get('tool_call_id') in tool_call_ids)
                ]
            
            # å¦‚æœæ˜¯ tool_resultï¼Œéœ€è¦ä»å¯¹åº”çš„ assistant æ¶ˆæ¯ä¸­ç§»é™¤ tool_call
            if chunk.chunk_type == ChunkType.TOOL_RESULT:
                tool_call_id = chunk.metadata.get('tool_call_id')
                if tool_call_id:
                    self._remove_tool_call_by_id(tool_call_id)
            
            # åˆ é™¤è¯­å—
            self.current_tokens -= chunk.tokens
            self.chunks = [c for i, c in enumerate(self.chunks) if i != index]
            return True
        return False
    
    def delete_chunks_from(self, index: int) -> int:
        """åˆ é™¤ä»æŒ‡å®šç´¢å¼•å¼€å§‹çš„æ‰€æœ‰è¯­å—ï¼ˆç”¨äºå›æ»šåˆ°æŸä¸ªç‚¹ï¼‰
        
        Args:
            index: åœ¨ self.chunks ä¸­çš„çœŸå®ç´¢å¼•
            
        Returns:
            åˆ é™¤çš„è¯­å—æ•°é‡
        """
        if index < 0 or index >= len(self.chunks):
            return 0
        
        # ä¸å…è®¸åˆ é™¤ç³»ç»Ÿæç¤ºè¯
        if self.chunks[index].chunk_type == ChunkType.SYSTEM:
            return 0
        
        # è®¡ç®—è¦åˆ é™¤çš„ token æ•°
        deleted_tokens = sum(c.tokens for c in self.chunks[index:])
        deleted_count = len(self.chunks) - index
        
        # æˆªæ–­
        self.chunks = self.chunks[:index]
        self.current_tokens -= deleted_tokens
        
        return deleted_count
    
    def edit_chunk_content(self, index: int, new_content: str) -> bool:
        """ç¼–è¾‘æŒ‡å®šè¯­å—çš„å†…å®¹
        
        Args:
            index: åœ¨ self.chunks ä¸­çš„çœŸå®ç´¢å¼•
            new_content: æ–°å†…å®¹
            
        Returns:
            æ˜¯å¦ç¼–è¾‘æˆåŠŸ
        """
        if 0 <= index < len(self.chunks):
            chunk = self.chunks[index]
            # ä¸å…è®¸ç¼–è¾‘ç³»ç»Ÿæç¤ºè¯
            if chunk.chunk_type == ChunkType.SYSTEM:
                return False
            
            # æ›´æ–°å†…å®¹å’Œ token æ•°
            old_tokens = chunk.tokens
            chunk.content = new_content
            chunk.tokens = 0
            chunk.estimate_tokens()
            self.current_tokens += chunk.tokens - old_tokens
            
            return True
        return False
    
    def get_chunk_preview(self, chunk: 'Chunk', max_length: int = 50) -> str:
        """è·å–è¯­å—çš„é¢„è§ˆæ–‡æœ¬
        
        Args:
            chunk: è¯­å—
            max_length: æœ€å¤§é•¿åº¦
            
        Returns:
            é¢„è§ˆæ–‡æœ¬
        """
        content = chunk.content.replace('\n', ' ').strip()
        if len(content) > max_length:
            content = content[:max_length - 3] + "..."
        return content
    
    def to_json(self) -> List[Dict[str, Any]]:
        """å¯¼å‡ºä¸ºJSONæ ¼å¼"""
        return [
            {
                "content": chunk.content,
                "type": chunk.chunk_type.value,
                "timestamp": chunk.timestamp.isoformat(),
                "tokens": chunk.tokens,
                "metadata": chunk.metadata
            }
            for chunk in self.chunks
        ]

    @classmethod
    def from_json(cls, data: List[Dict[str, Any]], max_tokens: int = 64000,
                  tools_schema: Optional[List[Dict]] = None) -> 'ChunkManager':
        """ä»JSONå¯¼å…¥

        Args:
            data: JSONæ ¼å¼çš„è¯­å—æ•°æ®
            max_tokens: æœ€å¤§tokenæ•°
            tools_schema: å·¥å…·å®šä¹‰schema

        Returns:
            æ–°çš„ChunkManagerå®ä¾‹
        """
        manager = cls(max_tokens=max_tokens, tools_schema=tools_schema)

        for item in data:
            chunk_type = ChunkType(item.get("type", "user"))
            content = item.get("content", "")

            # è§£ææ—¶é—´æˆ³
            timestamp_str = item.get("timestamp")
            if timestamp_str:
                try:
                    from datetime import datetime
                    timestamp = datetime.fromisoformat(timestamp_str)
                except Exception:
                    timestamp = datetime.now()
            else:
                timestamp = datetime.now()

            # åˆ›å»ºchunk
            chunk = Chunk(
                content=content,
                chunk_type=chunk_type,
                timestamp=timestamp,
                tokens=item.get("tokens", 0),
                metadata=item.get("metadata", {})
            )

            # å¦‚æœæ²¡æœ‰tokenæ•°ï¼Œé‡æ–°ä¼°ç®—
            if chunk.tokens == 0:
                chunk.estimate_tokens()

            manager.chunks.append(chunk)
            manager.current_tokens += chunk.tokens

        return manager    
